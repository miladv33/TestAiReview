name: CI/CD with Ollama Cache
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

permissions:
  contents: read
  pull-requests: write

env:
  OLLAMA_MODELS_DIR: ~/.ollama/models
  OLLAMA_VERSION: 0.1.27

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Cache Ollama Binary
        id: cache-ollama-binary
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/ollama
            /usr/local/bin/ollama
          key: ${{ runner.os }}-ollama-${{ env.OLLAMA_VERSION }}

      - name: Install Ollama
        if: steps.cache-ollama-binary.outputs.cache-hit != 'true'
        run: |
          sudo apt-get update
          sudo apt-get install -y curl wget jq
          mkdir -p ~/.cache/ollama
          OLLAMA_VERSION="v${{ env.OLLAMA_VERSION }}"
          echo "Using Ollama version: $OLLAMA_VERSION"
          DOWNLOAD_URL="https://github.com/ollama/ollama/releases/download/${OLLAMA_VERSION}/ollama-linux-amd64"
          echo "Downloading from: $DOWNLOAD_URL"
          if curl -L -o ollama-linux-amd64 "$DOWNLOAD_URL" && file ollama-linux-amd64 | grep -q "ELF"; then
            echo "Successfully downloaded Ollama binary"
          else
            echo "Failed to download valid Ollama binary"
            exit 1
          fi
          chmod +x ollama-linux-amd64
          sudo mv ollama-linux-amd64 /usr/local/bin/ollama
          if ! ollama --version; then
            echo "Failed to verify Ollama installation"
            exit 1
          fi
          cp /usr/local/bin/ollama ~/.cache/ollama/

      - name: Restore Ollama Binary
        if: steps.cache-ollama-binary.outputs.cache-hit == 'true'
        run: |
          sudo cp ~/.cache/ollama/ollama /usr/local/bin/
          sudo chmod +x /usr/local/bin/ollama
          ollama --version

      - name: Start Ollama Service
        run: |
          mkdir -p ~/.ollama
          ollama serve > ollama.log 2>&1 &
          timeout=30
          while [ $timeout -gt 0 ]; do
            if curl -s http://localhost:11434/api/version > /dev/null; then
              echo "Ollama service is ready"
              cat ollama.log
              break
            fi
            if grep -q "error" ollama.log; then
              echo "Error found in Ollama log:"
              cat ollama.log
              exit 1
            fi
            echo "Waiting for Ollama service to start... ($timeout seconds remaining)"
            sleep 1
            timeout=$((timeout - 1))
          done
          if [ $timeout -le 0 ]; then
            echo "Timeout waiting for Ollama service. Log contents:"
            cat ollama.log
            exit 1
          fi

      - name: Cache Ollama Models
        id: cache-ollama-models
        uses: actions/cache@v4
        with:
          path: ~/.ollama/models
          key: ${{ runner.os }}-ollama-models-${{ hashFiles('models.txt') }}-${{ env.OLLAMA_VERSION }}
          restore-keys: |
            ${{ runner.os }}-ollama-models-

      - name: Check Models File and Current Cache
        id: check-models
        run: |
          mkdir -p ~/.ollama/models
          
          # Read models from models.txt into an array
          declare -a required_models=()
          if [ -f "models.txt" ]; then
            while IFS= read -r model || [[ -n "$model" ]]; do
              if [[ ! -z "$model" && ! "$model" =~ ^# ]]; then
                required_models+=("$model")
              fi
            done < models.txt
          else
            required_models+=("llama2")
            echo "llama2" > models.txt
          fi
          
          # Check which models need to be downloaded
          declare -a models_to_download=()
          for model in "${required_models[@]}"; do
            if ! ollama list | grep -q "$model"; then
              models_to_download+=("$model")
            fi
          done
          
          # Export the list of models to download
          echo "MODELS_TO_DOWNLOAD=${models_to_download[*]}" >> $GITHUB_ENV
          
          if [ ${#models_to_download[@]} -gt 0 ]; then
            echo "needs_download=true" >> $GITHUB_OUTPUT
          else
            echo "needs_download=false" >> $GITHUB_OUTPUT
          fi

      - name: Download Missing Ollama Models
        if: steps.check-models.outputs.needs_download == 'true'
        run: |
          for model in $MODELS_TO_DOWNLOAD; do
            echo "Attempting to pull model: $model"
            max_retries=3
            retry_count=0
          
            while [ $retry_count -lt $max_retries ]; do
              if ollama pull "$model"; then
                echo "Successfully pulled model: $model"
                break
              fi
          
              retry_count=$((retry_count + 1))
              if [ $retry_count -eq $max_retries ]; then
                echo "Failed to pull model $model after $max_retries attempts"
                exit 1
              fi
          
              echo "Retry $retry_count pulling model $model..."
              sleep 5
            done
          done

      - name: Download Ollama Models
        if: steps.cache-ollama-models.outputs.cache-hit != 'true' && steps.check-models.outputs.models_exist == 'true'
        run: |
          mkdir -p ~/.ollama/models
          while IFS= read -r model || [[ -n "$model" ]]; do
            if [[ ! -z "$model" && ! "$model" =~ ^# ]]; then
              echo "Pulling model: $model"
              for i in {1..3}; do
                if ollama pull "$model"; then
                  break
                fi
                if [ $i -eq 3 ]; then
                  echo "Failed to pull model $model after 3 attempts"
                  exit 1
                fi
                echo "Retry $i pulling model $model..."
                sleep 5
              done
            fi
          done < models.txt

      - name: Debug Ollama Setup
        run: |
          echo "Ollama version: $(ollama --version)"
          echo "Available models: $(ollama list)"
          echo "Ollama service status: $(curl -s http://localhost:11434/api/version || echo 'not responding')"
          echo "Memory usage: $(free -h)"
          echo "Disk space: $(df -h)"


      - name: Fetch PR Changes
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            PR_NUMBER="${{ github.event.pull_request.number }}"
          else
            BRANCH_NAME=$(git rev-parse --abbrev-ref HEAD)
            PR_NUMBER=$(gh pr list --head "$BRANCH_NAME" --json number --jq '.[0].number')
          fi

          if [ -n "$PR_NUMBER" ]; then
            echo "Found PR number: $PR_NUMBER"
            PR_DATA=$(gh pr view $PR_NUMBER --json title,body,files,commits,reviews)

            echo "PR_CONTENT<<EOF" >> $GITHUB_ENV
            echo "$PR_DATA" | jq -r '"Title: " + .title + "\n\nDescription:\n" + .body + "\n\nChanges:\n" + (.files | map(.path + ":\n" + .patch) | join("\n\n")) + "\n\nCommits:\n" + (.commits | map(.messageHeadline) | join("\n"))' >> $GITHUB_ENV
            echo "EOF" >> $GITHUB_ENV
          else
            echo "No PR found, using direct diff..."
            echo "PR_CONTENT<<EOF" >> $GITHUB_ENV
            git diff HEAD^1 HEAD >> $GITHUB_ENV
            echo "EOF" >> $GITHUB_ENV
          fi

      - name: Review PR with Ollama
        id: ai-review
        run: |
          if [ -z "${{ env.PR_CONTENT }}" ]; then
            echo "Error: No PR content found to review"
            echo "REVIEW_TEXT=Error: No content found to review" >> $GITHUB_ENV
            exit 1
          fi
          
          PROMPT="You are an expert code reviewer. Analyze the following PR content and provide a concise review focusing on:
          1. Key changes and their purpose
          2. Technical concerns or improvements
          3. Security considerations
          4. Specific recommendations

          PR content:
          ${{ env.PR_CONTENT }}"
          
          REVIEW_OUTPUT=$(curl -s -X POST http://localhost:11434/api/generate \
            -H 'Content-Type: application/json' \
            -d "{
              \"model\": \"llama2\",
              \"prompt\": $(echo "$PROMPT" | jq -Rs .),
              \"stream\": false
            }" | jq -r '.response' | sed 's/\*\s*$//')
          
          # Format the output to remove trailing asterisks and extra newlines
          FORMATTED_OUTPUT=$(echo "$REVIEW_OUTPUT" | sed '/^[[:space:]]*$/d' | sed 's/\*/â€¢/g')
          
          echo "REVIEW_TEXT<<EOF" >> $GITHUB_ENV
          echo "$FORMATTED_OUTPUT" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV

      - name: Post AI Review to PR
        if: github.event_name == 'pull_request'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "## ðŸ¤– AI Code Review

          ${{ env.REVIEW_TEXT }}
          
          ---
          *This review was automatically generated by Ollama using the llama2 model*" > comment.md
          
          gh pr comment "${{ github.event.pull_request.number }}" --body-file comment.md

      - name: Build and Test
        run: echo "Building with cached Ollama models..."

      - name: Prepare Artifacts
        if: failure()
        run: |
          mkdir -p /tmp/ollama-artifacts/models
          mkdir -p /tmp/ollama-artifacts/logs
          cp -r ~/.ollama/models/* /tmp/ollama-artifacts/models/ || true
          cp ollama.log /tmp/ollama-artifacts/logs/ || true
          find /tmp/ollama-artifacts -type f -name "*:*" -exec bash -c 'mv "$1" "${1//:/\_}"' _ {} \;

      - name: Upload Cleaned Artifacts
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: ollama-artifacts
          path: /tmp/ollama-artifacts
          retention-days: 1

      - name: Cleanup
        if: always()
        run: |
          pkill ollama || true
          sleep 2